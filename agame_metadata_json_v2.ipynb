{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "309cbedc-0894-4d23-9956-ef9c6b72898d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deims in /opt/conda/lib/python3.11/site-packages (4.0)\n",
      "Requirement already satisfied: geopandas in /opt/conda/lib/python3.11/site-packages (from deims) (0.14.2)\n",
      "Requirement already satisfied: geopy in /opt/conda/lib/python3.11/site-packages (from deims) (2.4.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from deims) (2.1.1)\n",
      "Requirement already satisfied: fiona>=1.8.21 in /opt/conda/lib/python3.11/site-packages (from geopandas->deims) (1.9.5)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from geopandas->deims) (23.2)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /opt/conda/lib/python3.11/site-packages (from geopandas->deims) (3.6.1)\n",
      "Requirement already satisfied: shapely>=1.8.0 in /opt/conda/lib/python3.11/site-packages (from geopandas->deims) (2.0.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas->deims) (1.24.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->deims) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->deims) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas->deims) (2023.3)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in /opt/conda/lib/python3.11/site-packages (from geopy->deims) (2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas->deims) (23.1.0)\n",
      "Requirement already satisfied: click~=8.0 in /opt/conda/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas->deims) (8.1.7)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /opt/conda/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas->deims) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/conda/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas->deims) (0.7.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas->deims) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas->deims) (68.2.2)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from pyproj>=3.3.0->geopandas->deims) (2023.11.17)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: xmltodict in /opt/conda/lib/python3.11/site-packages (0.14.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install deims\n",
    "!pip install xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "966ed192-90a6-43f2-b833-d1cb333f7787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import json\n",
    "import xmltodict\n",
    "import deims\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06dac53f-721f-41a6-9f03-14f4135a564b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 139\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m#print(site_record)\u001b[39;00m\n\u001b[1;32m    138\u001b[0m uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://deims.org/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m deims_suffix\n\u001b[0;32m--> 139\u001b[0m site_record \u001b[38;5;241m=\u001b[39m \u001b[43mdeims\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetSiteById\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeims_suffix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m     site_name \u001b[38;5;241m=\u001b[39m site_record[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/deims.py:71\u001b[0m, in \u001b[0;36mgetSiteById\u001b[0;34m(site_id)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# open URL and parse as json\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(site_json_url) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 71\u001b[0m     parsed_site_json \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# optional processing steps\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# ...\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# returns entire site records as dict\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m parsed_site_json\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:482\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 482\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_safe_read\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m IncompleteRead:\n\u001b[1;32m    484\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:631\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_safe_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt):\n\u001b[1;32m    625\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \n\u001b[1;32m    627\u001b[0m \u001b[38;5;124;03m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;124;03m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m amt:\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(data))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/ssl.py:1311\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1308\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1309\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1310\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open('getcapabilities_1.3.0.xml') as fd:\n",
    "    doc = xmltodict.parse(fd.read())\n",
    "\n",
    "for layer in doc['WMS_Capabilities']['Capability']['Layer']['Layer']:\n",
    "\n",
    "    # date stamp of metadata update date\n",
    "    now = datetime.datetime.now()\n",
    "\n",
    "    # fetch EPSG code\n",
    "    epsg_code = ''\n",
    "    for value in layer['CRS']:\n",
    "        if \"EPSG:\" in value:\n",
    "            epsg_code = value[5:]\n",
    "\n",
    "    # boundaries\n",
    "    westBoundLongitude = float(layer['EX_GeographicBoundingBox'][\"westBoundLongitude\"])\n",
    "    eastBoundLongitude = float(layer['EX_GeographicBoundingBox'][\"eastBoundLongitude\"])\n",
    "    southBoundLatitude = float(layer['EX_GeographicBoundingBox'][\"southBoundLatitude\"])\n",
    "    northBoundLatitude = float(layer['EX_GeographicBoundingBox'][\"northBoundLatitude\"])\n",
    "\n",
    "    longitude_centre = (westBoundLongitude+eastBoundLongitude)/2.0\n",
    "    latitude_centre = (northBoundLatitude+southBoundLatitude)/2.0\n",
    "\n",
    "    keywords_to_be_printed = [\"eLTER\"]\n",
    "    record_uuid = None\n",
    "    authors = None\n",
    "    so_reference = None\n",
    "    # process keywords for site information and temporal extent\n",
    "    for keyword in layer['KeywordList']['Keyword']:\n",
    "        uri = None\n",
    "\n",
    "        if \"id: \" in keyword:\n",
    "            record_uuid = keyword[4:]\n",
    "            continue\n",
    "\n",
    "        if \"project: \" in keyword:\n",
    "            if \"e-shape\" in keyword:\n",
    "                project = {\n",
    "                    \"projectName\": \"e-shape\",\n",
    "                    \"projectID\": \"https://doi.org/10.3030/820852\"\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            if \"agame\" in keyword:\n",
    "                project = {\n",
    "                    \"projectName\": \"AGAME\",\n",
    "                    \"projectID\": \"https://www.umweltbundesamt.at/en/services/agame\"\n",
    "                }\n",
    "                continue\n",
    "\n",
    "        if \"variable: \" in keyword:\n",
    "            data_product_type = keyword[10:]\n",
    "            if data_product_type == \"Phenology\":\n",
    "                keyword = \"Phenology\"\n",
    "                uri = \"https://vocabs.lter-europe.net/EnvThes/21647\"\n",
    "                creators = [{\n",
    "                  \"creatorGivenName\": \"Saverio\",\n",
    "                  \"creatorFamilyName\": \"Vicario\",\n",
    "                  \"creatorEmail\": \"saverio.vicario@iia.cnr.it\",\n",
    "                  \"creatorIDs\": [{\n",
    "                      \"entityID\": \"https://orcid.org/0000-0003-1140-0483\",\n",
    "                      \"entityIDSchema\": \"Orcid\",\n",
    "                   }]\n",
    "                }]\n",
    "\n",
    "            if data_product_type == \"Hydroperiod\":\n",
    "                keyword = \"Hydroperiod\"\n",
    "                creators = [{\n",
    "                  \"creatorGivenName\": \"Ioannis\",\n",
    "                  \"creatorFamilyName\": \"Manakos\",\n",
    "                  \"creatorEmail\": \"imanakos@iti.gr\",\n",
    "                  \"creatorIDs\": [{\n",
    "                      \"entityID\": \"https://orcid.org/0000-0001-6833-294X\",\n",
    "                      \"entityIDSchema\": \"Orcid\",\n",
    "                    }]\n",
    "                }]\n",
    "\n",
    "            if data_product_type == \"Gross Primary Production\":\n",
    "                keyword = \"Gross Primary Production\"\n",
    "                uri = \"http://vocabs.lter-europe.net/EnvThes/21074\"\n",
    "                so_reference = {\n",
    "                    \"datasetTypeCode\": \"Gross Primary Production\",\n",
    "                    \"datasetTypeURI\": \"https://vocabs.lter-europe.net/so/090\"\n",
    "                }\n",
    "                creators = [{\n",
    "                    \"creatorGivenName\": \"Alberto\",\n",
    "                    \"creatorFamilyName\": \"Fuentes-Monjaraz\",\n",
    "                    \"creatorEmail\": \"mario.fuentesmonjaraz@deltares.nl\",\n",
    "                    \"creatorIDs\": [{\n",
    "                        \"entityID\": \"https://orcid.org/0000-0002-0711-8867\",\n",
    "                        \"entityIDSchema\": \"Orcid\",\n",
    "                    }]\n",
    "                },\n",
    "                {\n",
    "                    \"creatorGivenName\": \"Anna\",\n",
    "                    \"creatorFamilyName\": \"Spinosa\",\n",
    "                    \"creatorEmail\": \"anna.spinosa@deltares.nl\",\n",
    "                    \"creatorIDs\": [{\n",
    "                        \"entityID\": \"https://orcid.org/0000-0002-7921-5922\",\n",
    "                        \"entityIDSchema\": \"Orcid\",\n",
    "                    }]\n",
    "                },\n",
    "                {\n",
    "                  \"creatorGivenName\": \"Valeria\",\n",
    "                  \"creatorFamilyName\": \"Mobilia\",\n",
    "                  \"creatorEmail\": \"valeria.mobilia@deltares.nl\",\n",
    "                  \"creatorIDs\": [{\n",
    "                      \"entityID\": \"https://orcid.org/0000-0001-9370-598X\",\n",
    "                      \"entityIDSchema\": \"Orcid\",\n",
    "                    }]\n",
    "                }]\n",
    "\n",
    "            if data_product_type == \"snowcover\":\n",
    "                uri = \"https://vocabs.lter-europe.net/EnvThes/21559\"\n",
    "                keyword = \"snowCover\"\n",
    "                creators = [{\n",
    "                    \"creatorGivenName\": \"Maria\",\n",
    "                    \"creatorFamilyName\": \"Adamo\",\n",
    "                    \"creatorEmail\": \"adamo@iia.cnr.it\",\n",
    "                    \"creatorIDs\": [{\n",
    "                        \"entityID\": \"https://orcid.org/0000-0003-3030-4884\",\n",
    "                        \"entityIDSchema\": \"Orcid\",\n",
    "                     }]\n",
    "                },\n",
    "                {\n",
    "                    \"creatorGivenName\": \"Chiara\",\n",
    "                    \"creatorFamilyName\": \"Richiardi\",\n",
    "                    \"creatorEmail\": \"chiara.richiardi@iia.cnr.it\",\n",
    "                    \"creatorIDs\": [{\n",
    "                        \"entityID\": \"https://orcid.org/0000-0002-2370-7768\",\n",
    "                        \"entityIDSchema\": \"Orcid\",\n",
    "                     }]\n",
    "                }]\n",
    "\n",
    "        if \"site: \" in keyword:\n",
    "            deims_suffix = keyword[6:]\n",
    "            #print(site_record)\n",
    "            uri = \"https://deims.org/\" + deims_suffix\n",
    "            site_record = deims.getSiteById(deims_suffix)\n",
    "\n",
    "            try:\n",
    "                site_name = site_record[\"title\"]\n",
    "            except:\n",
    "                print(layer['Title'])\n",
    "                print(deims_suffix)\n",
    "            continue\n",
    "\n",
    "        if \"https://doi.org/\" in keyword:\n",
    "            doi = {\n",
    "                \"alternateID\": keyword,\n",
    "                \"alternateIDType\": \"DOI\"\n",
    "            }\n",
    "\n",
    "        if \"time: \" in keyword:\n",
    "            time_string = keyword[6:]\n",
    "\n",
    "            if \"-\" in time_string:\n",
    "                time_values = time_string.split('-')\n",
    "                period = [{\n",
    "                    \"startDate\": time_values[0] + '-01-01',\n",
    "                    \"endDate\": time_values[1] + '-12-31'\n",
    "                }]\n",
    "\n",
    "            else:\n",
    "                period = [{\n",
    "                    \"startDate\": time_string + '-01-01',\n",
    "                    \"endDate\": time_string + '-12-31'\n",
    "                }]\n",
    "            continue\n",
    "\n",
    "        if uri:\n",
    "            formatted_keyword = {\n",
    "                \"keywordLabel\": keyword,\n",
    "                \"keywordURI\": uri\n",
    "            }\n",
    "        else:\n",
    "            formatted_keyword = {\n",
    "                \"keywordLabel\": keyword,\n",
    "                \"keywordURI\": \"\"\n",
    "            }\n",
    "\n",
    "        keywords_to_be_printed.append(formatted_keyword)\n",
    "\n",
    "    #print(deims_suffix)\n",
    "\n",
    "    record = {\n",
    "        \"metadata\": {\n",
    "            \"alternateIdentifiers\": [doi],\n",
    "            \"titles\": [{\n",
    "                \"titleLanguage\": \"eng\",\n",
    "                \"titleText\": layer['Title']\n",
    "            }],\n",
    "            \"descriptions\": [{\n",
    "                \"type\": \"Abstract\",\n",
    "                \"descriptionText\": layer['Abstract'] # we could add a sentence that the metadata record was generated automatically\n",
    "            }],\n",
    "            \"keywords\": keywords_to_be_printed,\n",
    "            \"publicationDate\": datetime.datetime.now().strftime('%Y-%m-%d'),\n",
    "            \"language\": \"english\",\n",
    "            \"datasetType\": so_reference,\n",
    "            \"creators\": creators,\n",
    "            \"licenses\": [{\n",
    "                \"name\": \"CC BY 4.0\",\n",
    "                \"url\": \"https://creativecommons.org/licenses/by/4.0/deed.en\"\n",
    "            }],\n",
    "            \"geoLocations\": [\n",
    "                {\n",
    "                    \"geographicDescription\": site_record[\"title\"],\n",
    "                    \"point\": {\n",
    "                        \"longitude\": longitude_centre,\n",
    "                        \"latitude\": latitude_centre\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                      \"geographicDescription\": site_record[\"title\"],\n",
    "                      \"BoundingBox\": {\n",
    "                           \"westBoundLongitude\": westBoundLongitude,\n",
    "                           \"eastBoundLongitude\": eastBoundLongitude,\n",
    "                           \"southBoundLatitude\": southBoundLatitude,\n",
    "                           \"northBoundLatitude\": northBoundLatitude \n",
    "                      }\n",
    "                 }\n",
    "            ],\n",
    "            \"temporalCoverages\": period,\n",
    "            \"project\": project,\n",
    "            \"siteReference\": [{\n",
    "                \"name\": site_record[\"title\"],\n",
    "                \"PID\": deims_suffix\n",
    "            }],\n",
    "        },\n",
    "        \"files\": {\n",
    "            \"enabled\": False\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if project[\"projectName\"] == \"AGAME\":\n",
    "        record[\"metadata\"][\"methods\"][\"instrumentationDescription\"] = \"The methodology integrates multiple data sources via machine learning techniques to estimate Gross Primary Production (GPP) across different ecosystems. The process begins with data pre-processing, including the selection of sites based on criteria such available vegetation information, at least three full years of eddy covariance flux data. GPP and environmental data (e.g. air temperature, vapor pressure deficit, etc.) are extracted from the ICOS database across different ecosystem types. Then, different remote sensing (RS) indices (e.g NDVI, EVI, etc.) are estimated in GEE using Sentinel-2 MSI data as the mean value of the pixels found inside the climatological footprint 70 (an area were 70% of the GPP measurements are coming from). Both data coming from ICOS dataset and RS indices are used as predictors for the model. The data is split, with 70% used for training and 30% for testing. In the model setup, an XGBoost model is trained using the selected environmental and RS based indices. The model parameters are fine-tuned to improve accuracy. The remaining 30% of testing data is used to evaluate the model’s performance by comparing its predictions against in-situ GPP data. Error metrics like Mean Absolute Error (MAE), Root Mean Absolute Error (RMAE), and R² are provided. The maps computation phase applies the trained model to ecosystem boundaries from the DEIMS website to generate 5-day GPP maps.\"\n",
    "    \n",
    "    filename = record_uuid + \".json\"\n",
    "    base_dir = os.getcwd() + '/files_for_catalogue'\n",
    "    destination_path = os.path.join(base_dir, filename)\n",
    "\n",
    "    with open(destination_path, \"w+\") as f:\n",
    "        json.dump(record, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d25a380-ad62-45af-a714-a5288c6fabb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wohner/work/files_for_catalogue.zip'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to zip all generated files\n",
    "import shutil\n",
    "shutil.make_archive(\"files_for_catalogue\", 'zip', base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59d4971-0232-456a-931a-fc7707f3936d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
